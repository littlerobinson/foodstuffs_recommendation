# ğŸ² Foodstuffs Recommendation

A recommendation system designed to help you find similar food products based on a given item.

This tool enables consumers to choose alternative food substitutes to avoid allergens, opt for healthier options, or select more eco-friendly alternatives.

## ğŸ§© Project Components

This application consists of four main components:

- ğŸ¤– **Training**: Scripts for training machine learning models.
- ğŸ“ˆ **MLflow**: Tracks and manages machine learning experiments and models.
- ğŸ§‘â€ğŸ³ **API**: A FastAPI backend service to handle recommendations.
- ğŸ“Š **Dashboard**: A Streamlit-powered frontend for visualizing recommendations.

## ğŸš€ Getting Started

### Prerequisites

To run this project, ensure you have the following installed:

- **Docker**: [Download Docker](https://docs.docker.com/get-docker/)
- **Docker Compose**: [Download Docker Compose](https://docs.docker.com/compose/install/)
- **Poetry** (optional, for dependency management if developing locally): [Install Poetry](https://python-poetry.org/docs/)

### ğŸ—ï¸ Project Structure

```
project-root/
â”œâ”€â”€ api/                    # API service directory
â”‚   â”œâ”€â”€ main.py             # Entrypoint for FastAPI
â”œâ”€â”€ dashboard/              # Dashboard service directory
â”‚   â”œâ”€â”€ main.py             # Entrypoint for Streamlit
â”œâ”€â”€ training/               # Model training scripts
â”‚   â”œâ”€â”€ main.py             # Entrypoint for the ML pipeline
â”œâ”€â”€ data/                   # Directory for datasets
â”‚   â””â”€â”€ raw/                # Raw data storage
â”‚   â””â”€â”€ processed/          # Processed data storage
â”‚   â””â”€â”€ production/         # Clean database for API and Dashboard
â”‚   â””â”€â”€ product_images/     # Product images storages for training with image
â”œâ”€â”€ notebooks/              # Jupyter notebooks for exploratory analysis
â”œâ”€â”€ scripts/                # Project scripts
â”œâ”€â”€ docker/                 # Shared utilities and configuration
â”‚   â””â”€â”€ Dockerfile          # Dockerfile for the project
â”œâ”€â”€ docker-compose.yml      # Docker Compose file for service orchestration
â”œâ”€â”€ Makefile                # Makefile for automating tasks
â””â”€â”€ README.md               # Project documentation
```

## ğŸ› ï¸ Setup Instructions

1. **Clone the repository**:

   ```bash
   git clone https://github.com/littlerobinson/foodstuffs-recommendation
   cd foodstuffs-recommendation
   ```

2. **Download data**:

   Place the dataset in the `data/raw` directory:

   ```bash
   wget https://static.openfoodfacts.org/data/raw/en.openfoodfacts.org.products.csv.gz -P data/raw
   ```

3. **Build and start the containers**:

   With Docker and Docker Compose installed, start the application by running:

   ```bash
   make docker_up
   ```

   This command will build and start the API, dashboard, and MLflow services as defined in the `docker-compose.yml` file.

4. **ğŸŒ Accessing the Services**:

   - **API**: [http://localhost:8881](http://localhost:8881) ğŸ§‘â€ğŸ³
   - **Dashboard**: [http://localhost:8882](http://localhost:8882) ğŸ“Š
   - **MLflow**: [http://localhost:8883](http://localhost:8883) ğŸ“ˆ

## ğŸ”§ Development and Model Training

- **Model Training**: Run training scripts located in the `training` directory.
- **Datasets**: Place any required datasets in the `data` directory.
- **Exploratory Analysis**: Jupyter notebooks for research are available in the `notebooks` directory.

### Using the Makefile

To automate common tasks, you can use the Makefile. Here are the available commands:

- `make docker_up`: Build and start the Docker containers for API, dashboard, and MLflow.
- `make docker_down`: Stop and remove the Docker containers.
- `make docker_logs`: Visualize Docker logs for debugging.
- `make run`: Run the main machine learning pipeline (starts the training process for the machine learning model).
- `make load_data`: Load raw data using the configuration specified in `training/config.yaml`.
- `make mlflow`: Launch MLflow tracking service for managing experiments.
- `make install_deps`: Install dependencies with Poetry, including SpaCy's language model.
- `make clean`: Remove temporary and cache files from the project.
- `make run_tests`: Run unit and integration tests for both API and training components.

### Example

If you want to start the services and train the model in one go, you can use:

```bash
make docker_up && make run
```

## ğŸš€ Usage

After starting the services, you can:

- **API**: Make POST requests with product data to receive similar product recommendations.
- **Dashboard**: Interactively explore and visualize product recommendations.
- **MLflow**: Track metrics, hyperparameters, and model performance.

Enjoy discovering new products and exploring healthier, allergen-free, or eco-friendly alternatives! ğŸ¥³

## ğŸš€ Deployment exemple on Heroku

```bash
# Build the project images
docker compose build

#  Connection to Heroku and the container registry
heroku login
heroku container:login

# Tag image for Heroku register
docker tag <container-name> registry.heroku.com/<container-name>/web

#  Push image to Heroku
docker push registry.heroku.com/<container-name>/web

# Deploying the image
heroku container:release web -a <container-name>

```

## â• Advanced Features

1. **Sustainability Scoring**: Combine factors such as packaging, CO2 emissions, and product origins to create a custom environmental score. You can then analyze this scoreâ€™s correlation with product categories and processing levels.
2. **Nutri-Score Prediction**: Use product attributes to train a model that predicts a productâ€™s Nutri-Score or eco-score.
